{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72db44c4",
   "metadata": {},
   "source": [
    "## If error downloading weights due to firewall:\n",
    "Find the .deepface dicretory (https://stackoverflow.com/questions/76620093/keyerror-when-initializing-resnet-using-dlib-in-python)\n",
    "\n",
    "Search for the weights trying to download in the error message on google/git\n",
    "\n",
    "Download them and save them in the .deepface/weights folder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1edd06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "\n",
    "\n",
    "from deepface import DeepFace\n",
    "\n",
    "# from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd999f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a6fa6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/mnt/iDriveShare/Kayla/CBCT_images/anonymized/screenshots/'\n",
    "image_path_1 = PATH+\"19_1.png\"\n",
    "image_path_2 =  PATH+\"19_2.png\"\n",
    "image_path_A =  PATH+\"phantcrop.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af41b670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'face': array([[[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "         [[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "         [[0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        ]],\n",
       "  \n",
       "         ...,\n",
       "  \n",
       "         [[0.23921569, 0.22745098, 0.2       ],\n",
       "          [0.24313725, 0.23137255, 0.20392157],\n",
       "          [0.24705882, 0.23529412, 0.20784314],\n",
       "          ...,\n",
       "          [0.2627451 , 0.25098039, 0.22352941],\n",
       "          [0.25490196, 0.24313725, 0.21568627],\n",
       "          [0.24313725, 0.23137255, 0.20392157]],\n",
       "  \n",
       "         [[0.24705882, 0.23529412, 0.20784314],\n",
       "          [0.25098039, 0.23921569, 0.21176471],\n",
       "          [0.25098039, 0.23921569, 0.21176471],\n",
       "          ...,\n",
       "          [0.2627451 , 0.25098039, 0.22352941],\n",
       "          [0.2627451 , 0.25098039, 0.22352941],\n",
       "          [0.25882353, 0.24705882, 0.21960784]],\n",
       "  \n",
       "         [[0.26666667, 0.25490196, 0.22745098],\n",
       "          [0.27058824, 0.25882353, 0.23137255],\n",
       "          [0.27058824, 0.25882353, 0.23137255],\n",
       "          ...,\n",
       "          [0.2745098 , 0.2627451 , 0.23529412],\n",
       "          [0.27058824, 0.25882353, 0.23137255],\n",
       "          [0.26666667, 0.25490196, 0.22745098]]]),\n",
       "  'facial_area': {'x': 128,\n",
       "   'y': 51,\n",
       "   'w': 206,\n",
       "   'h': 206,\n",
       "   'left_eye': None,\n",
       "   'right_eye': None},\n",
       "  'confidence': 0.97}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DeepFace.extract_faces(image_path_1)#,enforce_detection=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee5ff83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verified': True,\n",
       " 'distance': 0.33751287778598194,\n",
       " 'threshold': 0.68,\n",
       " 'model': 'VGG-Face',\n",
       " 'detector_backend': 'opencv',\n",
       " 'similarity_metric': 'cosine',\n",
       " 'facial_areas': {'img1': {'x': 128,\n",
       "   'y': 51,\n",
       "   'w': 206,\n",
       "   'h': 206,\n",
       "   'left_eye': None,\n",
       "   'right_eye': None},\n",
       "  'img2': {'x': 153,\n",
       "   'y': 59,\n",
       "   'w': 180,\n",
       "   'h': 180,\n",
       "   'left_eye': None,\n",
       "   'right_eye': None}},\n",
       " 'time': 0.56}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DeepFace.verify(img1_path = image_path_1, img2_path = image_path_2, enforce_detection=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6461c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: DOWNLOAD WEIGHTS\n",
    "# DeepFace.analyze(img_path = image_path_1, actions = ['age', 'gender', 'race', 'emotion']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7b6b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
